{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### **(?): shows where you need to write code**"
   ],
   "metadata": {
    "id": "fd9uRzcKqF66"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (?) Go to the location of the data"
   ],
   "metadata": {
    "id": "qqRLu210ybgI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mount the notebook to your google drive, and then you can access the files in google drive"
   ],
   "metadata": {
    "id": "RJ4BMnjjkAwe"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G67a5_bXf4IH",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "af9c62e8-bb87-4d95-9601-8c1693635b85"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(?) Switch to the corona folder**\n",
    "\n",
    "command: %cd /content/drive/MyDrive/.../corona\n",
    "\n",
    "'...' means the path from 'MyDrive' to the 'corona' folder, which needs to be filled in according to where you put the 'corona' folder"
   ],
   "metadata": {
    "id": "ewmp37banoUZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%cd /content/drive/MyDrive/"
   ],
   "metadata": {
    "id": "TlRmPCP7oR0o",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5c61b78c-410d-407a-e0d4-d832c0fded35"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Check if the directory is correct**\n",
    "\n",
    "If correct, you will find \"data\", \"corona_questions\", and \"corona.ipynb\" in the output"
   ],
   "metadata": {
    "id": "9d6UjPpSpAGQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!ls"
   ],
   "metadata": {
    "id": "TasOlon7pOgJ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0a8c51c0-7f93-4c51-eaab-bd4d85eae26a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (?) (optional) Package"
   ],
   "metadata": {
    "id": "R4KAhw_Bokwl"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Import packages**"
   ],
   "metadata": {
    "id": "AqkJUFI-bYvo"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat, savemat\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2"
   ],
   "metadata": {
    "id": "sJviRB4jodkV"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(?) (optional) Other packages**\n",
    "\n",
    "If you want to use some packages that are not imported above, please write in the block below; if not, you can ignore this block"
   ],
   "metadata": {
    "id": "u1KDs_Apx16W"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "16Ka-MLQVYzi"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (?) Data"
   ],
   "metadata": {
    "id": "6eFqkVitVg82"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> In this project, the model is designed for complex-valued video, you need to read the file and treat it as a complex-valued video, whether it is a complex-valued video or a real-valued video, and then store it as real-valued data"
   ],
   "metadata": {
    "id": "ECvDrBueeu_8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> In the data folder, there are 9 MAT files, and each file has three 3D arrays of size (H,W,T<sub>total</sub>):\n",
    "> * D: raw data, original video\n",
    "> * L: low rank part, background\n",
    "> * S: sparse part, foreground\n",
    ">\n",
    "> where H is the height of the frame, W is the width of the frame, and T<sub>total</sub> is the total number of frames in the video. Also, the frame size has been resized to 100*100 (meaning H = W = 100)"
   ],
   "metadata": {
    "id": "dgqfW3VcVikS"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(?) Read files and Get data**\n",
    "\n",
    "Description: You already know the location of the files containing the videos, please read them and gather and organize the data.\n",
    "\n",
    "Requirements:\n",
    "1. You need to sample a continuous segment of length T (num_frames in the code) from the video every few frames (stride in the code), each segment of size (H,W,T)\n",
    "2. Because the model only accepts real-valued data, and the segment is complex-valued, it is necessary to concatenate the real and imaginary parts of the video along the third dimension.\n",
    " * Size changed from (H,W,T) to (H,W,T2), where T2 = T × 2, the first T 2D arrays are the real part of the segment, and the last T 2D arrays are the imaginary part of the segment\n",
    "3. Function I/O\n",
    " * Input: A MAT file, num_frames, stride\n",
    " * Output: D, L, S (the size should be (N,1,H,W,T2), where N is the number of segments of size (H,W,T2))\n",
    "\n",
    "Hint:\n",
    "* Given a tensor A of size (H,W,T), what is the size of B = A[None, ...]?"
   ],
   "metadata": {
    "id": "x_T9MKyPVj2C"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_data(file, num_frames=40, stride=10):\n",
    "    data = loadmat(file, mat_dtype=True)\n",
    "    D, L, S = data[\"D\"], data[\"L\"], data[\"S\"]\n",
    "    D = D.astype(np.complex64)\n",
    "\n",
    "    segments = []\n",
    "    for i in range(0, D.shape[2] - num_frames + 1, stride):\n",
    "        segment_D = D[:, :, i:i + num_frames]\n",
    "        segment_L = L[:, :, i:i + num_frames]\n",
    "        segment_S = S[:, :, i:i + num_frames]\n",
    "        segments.append((segment_D, segment_L, segment_S))\n",
    "\n",
    "    segments = np.array(segments)\n",
    "\n",
    "    segments_complex = segments.astype(np.complex64)\n",
    "    segments_real = np.real(segments_complex)\n",
    "    segments_imag = np.imag(segments_complex)\n",
    "    segments_concat = np.concatenate((segments_real, segments_imag), axis=-1)\n",
    "\n",
    "    return torch.from_numpy(np.expand_dims(segments_concat[:, 0], axis=1)), torch.from_numpy(np.expand_dims(segments_concat[:, 1], axis=1)), torch.from_numpy(np.expand_dims(segments_concat[:, 2], axis=1))\n",
    "# get_data('data/Board.mat')"
   ],
   "metadata": {
    "id": "fq1gY8bRVmOl"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(?) Build a custom dataset using the data you get from 'get_data'**\n",
    "\n",
    "Requirement:\n",
    "1. You now get D, L, S, please build a custom dataset for loading data\n",
    "\n",
    "Note:\n",
    "1. Image transformation is not necessary, it's up to you"
   ],
   "metadata": {
    "id": "0Khx0QN7Vq9T"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, D, L, S, transform=None):\n",
    "        self.D, self.L, self.S = D, L, S\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.D)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.D[index],\n",
    "        y = (self.L[index], self.S[index])\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return x, y"
   ],
   "metadata": {
    "id": "rChqoi3IVvfT"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (?) Model"
   ],
   "metadata": {
    "id": "_fNp3CEcsEJC"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> You'll be writing code for soft thresholding in your model, so here's a brief description of what soft thresholding is and how to use it\n",
    ">\n",
    "> * Hard thresholding will turn values close to 0 directly to 0, while soft thresholding will move all values closer to 0 (too close will directly become 0)\n",
    ">\n",
    "> * Using a soft threshold with $ℓ_1$-norm can make variables sparse, in practice you can often see many people use it because $ℓ_1$-norm has good properties (convex, continuous, sub-differentiable)\n",
    ">\n",
    "> * Suppose now you have a variable $x$ (scalar or vector) and a threshold $t \\geq 0$, you can do soft thresholding on $x$ as follows:\n",
    ">\n",
    ">  1. Change $x = ||x||_2 × \\frac{x}{||x||_2}$, the first part shows the magnitude and the second part shows the direction\n",
    ">  2. We do the thresholding on the magnitude, so change the magnitude to ReLU$(||x||_2 - t)$\n",
    ">  3. The result $x'=$ ReLU$(||x||_2 - t) × \\frac{x}{||x||_2} = (||x||_2 - t)_{+} × \\frac{x}{||x||_2}$\n",
    "> * From the above example, you can find that the most important thing is to find an appropriate threshold $t$, which is what we want the model to learn\n",
    ">"
   ],
   "metadata": {
    "id": "7iWlXTIrZ2Bd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(?) Complex Convolutional 3D Layer**\n",
    "\n",
    "From the equation:\n",
    "\n",
    "Y = X × W \\\\\n",
    "= Y<sub>real</sub> + jY<sub>imag</sub>\n",
    "= (X<sub>real</sub> + jX<sub>imag</sub>) × (W<sub>real</sub> + jW<sub>imag</sub>) \\\\\n",
    "= X<sub>real</sub> × W<sub>real</sub> + X<sub>real</sub> × jW<sub>imag</sub> + jXi × W<sub>real</sub> + jX<sub>imag</sub> × jW<sub>imag</sub> \\\\\n",
    "= (X<sub>real</sub> × W<sub>real</sub> - X<sub>imag</sub> × W<sub>imag</sub>) + j(X<sub>real</sub> × W<sub>imag</sub> + X<sub>imag</sub> × W<sub>real</sub>)\n",
    "\n",
    "We can easily find out how to directly use the real and imaginary parts of the input and weight to get the correct result Y<sub>real</sub>, Y<sub>imag</sub> (all are real-valued)\n",
    "\n",
    "Requirements:\n",
    "* Please complete the forward function, note that X and Y are the same size"
   ],
   "metadata": {
    "id": "TMOPuD8VPNl9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Conv3dC(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(Conv3dC, self).__init__()\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        self.convR = nn.Conv3d(1, 1, kernel_size=kernel_size, padding='same')  # W_real\n",
    "        self.convI = nn.Conv3d(1, 1, kernel_size=kernel_size, padding='same')  # W_imag\n",
    "\n",
    "    def forward(self, X):\n",
    "        T = X.shape[-1] // 2\n",
    "        R = X[..., :T]\n",
    "        I = X[..., T:]\n",
    "        Y = torch.concat([self.convR(R) - self.convI(I), self.convR(I) + self.convI(R)], dim=-1)\n",
    "        return Y\n"
   ],
   "metadata": {
    "id": "Mu2q1IWyPNQN"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Combination of three Complex Convolutional 3D Layers**"
   ],
   "metadata": {
    "id": "2avLScmbkTz7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Conv3dCx3(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(Conv3dCx3, self).__init__()\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        self.convD = Conv3dC(kernel_size)\n",
    "        self.convL = Conv3dC(kernel_size)\n",
    "        self.convS = Conv3dC(kernel_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        D, L, S = X\n",
    "        D = self.convD(D)\n",
    "        L = self.convL(L)\n",
    "        S = self.convS(S)\n",
    "        return D + L + S"
   ],
   "metadata": {
    "id": "U_yFlym3rxkz"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(?) Singular Value Thresholding (SVT)**\n",
    "\n",
    "Description:\n",
    "* SVT is used to make the matrix low rank, the principle is to make the singular value sparse\n",
    "* Learnable parameter: lambda_L\n",
    "* Threshold: sigmoid(lambda_L) × coeff_L × maximum singular value\n",
    "* Each segment (containing many frames) has a threshold\n",
    "* Reshape input of size (N,1,H,W,T2) to (N,1,H×W,T2) and convert it to a complex-valued version of size (N,1,H×W,T), and do sigular value thresholding for each sample of size (H×W,T)\n",
    "\n",
    "Requirements:\n",
    "* Please complete the forward function\n",
    "\n",
    "Hints:\n",
    "* Convert the array to the complex-valued version before thresholding\n",
    "* X and Y are the same size"
   ],
   "metadata": {
    "id": "pDMhUbR3kZMa"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class SVT(nn.Module):\n",
    "    def __init__(self, coeff_L):\n",
    "        super(SVT, self).__init__()\n",
    "\n",
    "        self.coeff_L = coeff_L\n",
    "        self.lambda_L = nn.Parameter(torch.zeros(1, requires_grad=True))\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X):\n",
    "        s = X.shape\n",
    "        X = X.reshape([s[0], s[1], s[2] * s[3], s[4]])\n",
    "        t = s[4] // 2\n",
    "        XC = torch.complex(X[..., :t], X[..., t:])\n",
    "\n",
    "        # one = X[0,0,:,0]\n",
    "        # one = one.reshape([100,100])\n",
    "        # fig, axs = plt.subplots(1, 1, figsize=(15, 3))\n",
    "        # axs.imshow(one.detach().cpu().numpy(), cmap='gray')\n",
    "        # plt.show()\n",
    "\n",
    "        U, S, Vt = torch.linalg.svd(XC, full_matrices=False)\n",
    "        a = self.sigmoid(self.lambda_L) * self.coeff_L * S.max(dim=-1).values\n",
    "        S_tr = torch.diag_embed(self.relu(S - a.reshape([s[0], 1, 1]))).type(torch.complex64)\n",
    "        # print(f'{S_tr.shape = }')\n",
    "        # print(f'{S_tr.dtype = }')\n",
    "        # print(f'{U.shape = }')\n",
    "        # print(f'{U.dtype = }')\n",
    "        # print(f'{Vt.shape = }')\n",
    "        # print(f'{Vt.dtype = }')\n",
    "\n",
    "        Y = U @ S_tr @ Vt\n",
    "        Y = torch.concat([Y.real, Y.imag], dim=-1).reshape(s)\n",
    "\n",
    "        return Y"
   ],
   "metadata": {
    "id": "Y_yD0EiysKGC"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(?) Soft Thresholding (SFT)**\n",
    "\n",
    "Description:\n",
    "* SFT is used to make the array sparse\n",
    "* Learnable parameter: lambda_S\n",
    "* Threshold: sigmoid(lambda_S) × coeff_S × (root) mean square of elements per frame\n",
    "* Each frame has a threshold\n",
    "\n",
    "Requirements:\n",
    "* Please complete the forward function\n",
    "\n",
    "Hints:\n",
    "* Convert the array to the complex-valued version before thresholding\n",
    "* X and Y are the same size"
   ],
   "metadata": {
    "id": "XTZYIQkikmKU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class SFT(nn.Module):\n",
    "    def __init__(self, coeff_S):\n",
    "        super(SFT, self).__init__()\n",
    "\n",
    "        self.coeff_S = coeff_S\n",
    "        self.lambda_S = nn.Parameter(torch.zeros(1, requires_grad=True))\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X):\n",
    "        s = X.shape\n",
    "        X = X.reshape([s[0], s[1], s[2] * s[3], s[4]])\n",
    "        t = s[4] // 2\n",
    "        XC = torch.complex(X[..., :t], X[..., t:])\n",
    "\n",
    "        a = self.sigmoid(self.lambda_S) * self.coeff_S * torch.sqrt((XC ** 2).mean(dim=[-2, -1]))\n",
    "        tr = 1 - a / torch.linalg.norm(XC, 2, dim=[-2, -1])\n",
    "        Y = (self.relu(tr.real) + 1.j * self.relu(tr.imag)).reshape((s[0], s[1], 1, 1)) * XC\n",
    "        Y = torch.concat([Y.real, Y.imag], dim=-1).reshape(s)\n",
    "        return Y"
   ],
   "metadata": {
    "id": "IOLdiIhbsOBx"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**ISTA Cell**\n",
    "\n",
    "Including Conv3dx3, SVT, SFT"
   ],
   "metadata": {
    "id": "oSiTDzS5l4hC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class ISTACell(nn.Module):\n",
    "    def __init__(self, kernel_size, coeff_L, coeff_S):\n",
    "        super(ISTACell, self).__init__()\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.coeff_L = coeff_L\n",
    "        self.coeff_S = coeff_S\n",
    "\n",
    "        self.netL = nn.Sequential(Conv3dCx3(kernel_size), SVT(coeff_L))\n",
    "        self.netS = nn.Sequential(Conv3dCx3(kernel_size), SFT(coeff_S))\n",
    "\n",
    "    def forward(self, X):\n",
    "        D = X[0]\n",
    "        L = self.netL(X)\n",
    "        S = self.netS(X)\n",
    "\n",
    "        Y = torch.zeros(X.shape).to(X.device)\n",
    "        Y[0], Y[1], Y[2] = D, L, S\n",
    "        return Y"
   ],
   "metadata": {
    "id": "4D7eF2XHsUUi"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(?) Deep Network: Convolutional rObust pRincipal cOmpoNent Analysis (CORONA)**\n",
    "\n",
    "Description:\n",
    "* kernel_list contains some integers, each integer k can be used to set the kernel_size = [k,k,1] of the corresponding layer\n",
    "\n",
    "Requirement:\n",
    "* Construct the network called 'net'\n",
    "\n",
    "Hint:\n",
    "* Please read ISTACell cell first\n",
    "* You may need 'nn.Sequential(*layers)'"
   ],
   "metadata": {
    "id": "cJVjpmSrmG3J"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class CORONA(nn.Module):\n",
    "    def __init__(self, kernel_list, coeff_L=0.4, coeff_S=1.8):\n",
    "        super(CORONA, self).__init__()\n",
    "        self.kernel_list = kernel_list\n",
    "        self.coeff_L = coeff_L\n",
    "        self.coeff_S = coeff_S\n",
    "\n",
    "        self.net = nn.Sequential(*[ISTACell(layer, self.coeff_L, self.coeff_S) for layer in kernel_list])\n",
    "\n",
    "    def forward(self, D):\n",
    "        X = torch.zeros([3] + list(D.shape)).to(D.device)\n",
    "        X[0] = D\n",
    "        X = self.net(X)\n",
    "        L, S = X[1], X[2]\n",
    "        return L, S"
   ],
   "metadata": {
    "id": "qePcOBxBsaD5"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compute loss\n",
    "\n",
    "Input:\n",
    "* target = (target_L, target_S)"
   ],
   "metadata": {
    "id": "xDQf4kMzCie3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_loss(net, input_D, target, alpha=0.5):\n",
    "    output_L, output_S = net(input_D)\n",
    "    target_L, target_S = target\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    loss_L = criterion(output_L, target_L)\n",
    "    loss_S = criterion(output_S, target_S)\n",
    "    loss = alpha * loss_L + (1 - alpha) * loss_S\n",
    "\n",
    "    return loss"
   ],
   "metadata": {
    "id": "pwRySj-zCliH"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Function for constructing videos\n",
    "\n",
    "Input:\n",
    "* images_array is of size (H,W,T)"
   ],
   "metadata": {
    "id": "g6h0T52zXbA5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def array_to_gray_video(images_array, video_name, fps=30):\n",
    "    # Get the height and width of the video, assuming all frames have the same size\n",
    "    height, width = images_array.shape[0], images_array.shape[1]\n",
    "\n",
    "    # Set the video codec to mp4\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "\n",
    "    # Create a VideoWriter object, with parameters for the output file name, codec, frame rate, and size\n",
    "    video = cv2.VideoWriter(video_name, fourcc, fps, (width, height), isColor=False)\n",
    "\n",
    "    # Write each frame in the numpy array to the output video\n",
    "    for i in range(images_array.shape[2]):\n",
    "        image = images_array[:, :, i]\n",
    "        image = np.uint8(image)  # Convert to uint8 format\n",
    "        video.write(image)\n",
    "\n",
    "    # Release the resources used by the VideoWriter and destroy any OpenCV windows\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()"
   ],
   "metadata": {
    "id": "7mUfAEMjjXro"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (?) Main"
   ],
   "metadata": {
    "id": "JQVyhkAlWCOT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Decide which device to use"
   ],
   "metadata": {
    "id": "yNvwVd1mAZFR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda')"
   ],
   "metadata": {
    "id": "jOqucvKo6O3A"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(?) Get data**\n",
    "\n",
    "Requirements:\n",
    "* Get data from the files and concatenate them\n",
    "* Build datasets and dataloaders"
   ],
   "metadata": {
    "id": "dcH5PHFcJwzI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "torch.cuda.empty_cache()\n",
    "#(?) There are many files in the data folder, please collect them into file_list\n",
    "#   Hint: You may need 'os.listdir'\n",
    "path = 'data'\n",
    "file_list = os.listdir(path)\n",
    "print(file_list)\n",
    "\n",
    "#(?) Input each file in file_list to get_data one by one, and then\n",
    "#   concatenate the D obtained from each file along the first dimension.\n",
    "#   Do the same operations on L and S, resulting in three arrays\n",
    "#   of equal size (D, L, and S)\n",
    "\n",
    "D_list, L_list, S_list = [], [], []\n",
    "for file in file_list:\n",
    "    Di, Li, Si = get_data(path + '/' + file)\n",
    "    D_list.append(Di)\n",
    "    L_list.append(Li)\n",
    "    S_list.append(Si)\n",
    "\n",
    "D, L, S = torch.cat(D_list, dim=0).to(device), torch.cat(L_list, dim=0).to(device), torch.cat(S_list, dim=0).to(device)\n",
    "\n",
    "#(?) Use the custom dataset to build a dataset with the obtained array D, L, and S\n",
    "data = CustomDataset(D, L, S)\n",
    "\n",
    "#(?) Split the dataset into the training part (80%) and the validation part (20%)\n",
    "#   Hint: You may need 'random_split'\n",
    "train_size = int(0.8 * len(data))\n",
    "valid_size = len(data) - train_size\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(data, [train_size, valid_size])\n",
    "\n",
    "#(?) Create train_loader and valid_loader using train_set and valid_set\n",
    "#   Hint: Set the batch size to be less than or equal to 4, or you may get an out-of-memery error\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "id": "ZrqzVWd3WDY6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6d229432-2643-4173-9e68-24b02415a750"
   },
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Board.mat', 'Candela_m1.mat', 'CAVIAR1.mat', 'CaVignal.mat', 'HallAndMonitor.mat', 'HighwayI.mat', 'HighwayII.mat', 'IBMtest2.mat', 'Snellen.mat']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a model"
   ],
   "metadata": {
    "id": "sgQ45gWfL69h"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "kernel_list = [5] * 2\n",
    "coeff_L = 0.4\n",
    "coeff_S = 1.8\n",
    "net = CORONA(kernel_list, coeff_L=coeff_L, coeff_S=coeff_S)\n",
    "net = net.to(device)"
   ],
   "metadata": {
    "id": "WAtEDouWL7WB"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(?) Train the model**\n",
    "\n",
    "Requirements:\n",
    "* Determine the optimizer\n",
    "* Finish the training process\n",
    "\n",
    "Note:\n",
    "* It takes about 2 hours to complete 100 epochs, you can test it with smaller max_epochs to confirm whether the code is correct"
   ],
   "metadata": {
    "id": "Dm6QET0qMgso"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "max_epochs = 100\n",
    "alpha = 0.5\n",
    "\n",
    "#(?) Optimizer\n",
    "optimizer = torch.optim.Adam(lr=6e-3, params=net.parameters())\n",
    "\n",
    "#\n",
    "min_valid_loss = np.inf\n",
    "\n",
    "# Container of the results\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    #(?) Use 'train_loader' to update the model\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    for i, ([D], target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        loss = get_loss(net, D, target)\n",
    "        train_loss += loss.detach()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 5 == 0:\n",
    "            print(f'{i}th batch')\n",
    "    train_loss /= train_size / batch_size\n",
    "    train_loss_list.append(train_loss.cpu())\n",
    "\n",
    "    #(?) Use 'train_loader' and 'valid_loader' to evaluate the model\n",
    "    #   Compute train_loss and valid_loss and append them to train_loss_list and valid_loss_list respectively\n",
    "    net.eval()\n",
    "    valid_loss = 0\n",
    "    for [D], target in valid_loader:\n",
    "        valid_loss += get_loss(net, D, target).detach()\n",
    "    valid_loss /= valid_size / batch_size\n",
    "    valid_loss_list.append(valid_loss.cpu())\n",
    "\n",
    "    # Use validation loss to determine the best model\n",
    "    if valid_loss < min_valid_loss:\n",
    "        net_best = net\n",
    "        min_valid_loss = valid_loss\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f'Epoch {epoch} completed')\n",
    "\n",
    "net = net_best"
   ],
   "metadata": {
    "id": "raFbk0juMjLX",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "a3ac7b0c-e609-43fb-cb5a-773e6bfc6ee1"
   },
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 0 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 1 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 2 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 3 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 4 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 5 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 6 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 7 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 8 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 9 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 10 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 11 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 12 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 13 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 14 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 15 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 16 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 17 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 18 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 19 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 20 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 21 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 22 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 23 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 24 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 25 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 26 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 27 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 28 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 29 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 30 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 31 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 32 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 33 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 34 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 35 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 36 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 37 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 38 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 39 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 40 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 41 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 42 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 43 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 44 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 45 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 46 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 47 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 48 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 49 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 50 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 51 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 52 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 53 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 54 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 55 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 56 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 57 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 58 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 59 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 60 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 61 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 62 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 63 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 64 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 65 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 66 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 67 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 68 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 69 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 70 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 71 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 72 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 73 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 74 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 75 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 76 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 77 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 78 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 79 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 80 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 81 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 82 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 83 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 84 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 85 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 86 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 87 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 88 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 89 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 90 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 91 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n",
      "15th batch\n",
      "20th batch\n",
      "25th batch\n",
      "Epoch 92 completed\n",
      "0th batch\n",
      "5th batch\n",
      "10th batch\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "svd_backward: The singular vectors in the complex case are specified up to multiplication by e^{i phi}. The specified loss function depends on this phase term, making it ill-defined.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 22\u001B[0m\n\u001B[0;32m     20\u001B[0m loss \u001B[38;5;241m=\u001B[39m get_loss(net, D, target)\n\u001B[0;32m     21\u001B[0m train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mdetach()\n\u001B[1;32m---> 22\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m5\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:522\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    512\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    513\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    514\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    515\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    520\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    521\u001B[0m     )\n\u001B[1;32m--> 522\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    524\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    261\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    263\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    264\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 266\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    274\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: svd_backward: The singular vectors in the complex case are specified up to multiplication by e^{i phi}. The specified loss function depends on this phase term, making it ill-defined."
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(?) Save the model and the results**\n",
    "\n",
    "Requirements:\n",
    "* Create a folder\n",
    "* Save the model (net) and results (training/validation loss list) to the folder\n",
    "\n",
    "Hint:\n",
    "* You can use 'Path().mkdir()' to create a folder\n",
    "* You can use 'torch.save' to save the model\n",
    "* You use 'np.savez' to save the results"
   ],
   "metadata": {
    "id": "jjoH-wUYVIjX"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_folder = 'model'\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "model_path = model_folder+'/model_data_2layers.pth'\n",
    "\n",
    "torch.save(net.state_dict(), model_path)"
   ],
   "metadata": {
    "id": "KjQhHpSqVnLt"
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Uploading model for a test."
   ],
   "metadata": {
    "id": "pBSGS8qZ0wem"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = CORONA(kernel_list, coeff_L=coeff_L, coeff_S=coeff_S)\n",
    "model.load_state_dict(torch.load(model_folder+'/model_data_2layers.pth'))\n",
    "model.eval()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K2dKv4Y70wEO",
    "outputId": "d9291181-9f2f-4ed6-d35c-7b6ee2da339e"
   },
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "CORONA(\n  (net): Sequential(\n    (0): ISTACell(\n      (netL): Sequential(\n        (0): Conv3dCx3(\n          (convD): Conv3dC(\n            (convR): Conv3d(1, 1, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=same)\n            (convI): Conv3d(1, 1, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=same)\n          )\n          (convL): Conv3dC(\n            (convR): Conv3d(1, 1, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=same)\n            (convI): Conv3d(1, 1, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=same)\n          )\n          (convS): Conv3dC(\n            (convR): Conv3d(1, 1, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=same)\n            (convI): Conv3d(1, 1, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=same)\n          )\n        )\n        (1): SVT(\n          (relu): ReLU(inplace=True)\n          (sigmoid): Sigmoid()\n        )\n      )\n      (netS): Sequential(\n        (0): Conv3dCx3(\n          (convD): Conv3dC(\n            (convR): Conv3d(1, 1, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=same)\n            (convI): Conv3d(1, 1, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=same)\n          )\n          (convL): Conv3dC(\n            (convR): Conv3d(1, 1, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=same)\n            (convI): Conv3d(1, 1, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=same)\n          )\n          (convS): Conv3dC(\n            (convR): Conv3d(1, 1, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=same)\n            (convI): Conv3d(1, 1, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=same)\n          )\n        )\n        (1): SFT(\n          (relu): ReLU()\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n    (1): ISTACell(\n      (netL): Sequential(\n        (0): Conv3dCx3(\n          (convD): Conv3dC(\n            (convR): Conv3d(1, 1, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=same)\n            (convI): Conv3d(1, 1, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=same)\n          )\n          (convL): Conv3dC(\n            (convR): Conv3d(1, 1, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=same)\n            (convI): Conv3d(1, 1, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=same)\n          )\n          (convS): Conv3dC(\n            (convR): Conv3d(1, 1, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=same)\n            (convI): Conv3d(1, 1, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=same)\n          )\n        )\n        (1): SVT(\n          (relu): ReLU(inplace=True)\n          (sigmoid): Sigmoid()\n        )\n      )\n      (netS): Sequential(\n        (0): Conv3dCx3(\n          (convD): Conv3dC(\n            (convR): Conv3d(1, 1, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=same)\n            (convI): Conv3d(1, 1, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=same)\n          )\n          (convL): Conv3dC(\n            (convR): Conv3d(1, 1, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=same)\n            (convI): Conv3d(1, 1, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=same)\n          )\n          (convS): Conv3dC(\n            (convR): Conv3d(1, 1, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=same)\n            (convI): Conv3d(1, 1, kernel_size=(5, 5, 5), stride=(1, 1, 1), padding=same)\n          )\n        )\n        (1): SFT(\n          (relu): ReLU()\n          (sigmoid): Sigmoid()\n        )\n      )\n    )\n  )\n)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(?) Plot the figures**\n",
    "\n",
    "Requirements:\n",
    "* Create a folder called 'fig_folder' and save the figure in this folder"
   ],
   "metadata": {
    "id": "fw5fiNvQVnyd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#(?) Create a folder called 'fig_folder'\n",
    "\n",
    "\n",
    "os.makedirs('fig_folder', exist_ok=True)\n",
    "fig_folder='fig_folder'\n",
    "\n",
    "#\n",
    "num_epochs = len(train_loss_list)\n",
    "x_range = np.arange(num_epochs) + 1\n",
    "\n",
    "# Plot training/validation loss\n",
    "plt.figure()\n",
    "plt.plot(x_range, train_loss_list, label='Training')\n",
    "plt.plot(x_range, valid_loss_list, label='Validation')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch index')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "#(?) Save the loss curves figure\n",
    "plt.savefig(fig_folder + '/loss_plot_2layer.png')"
   ],
   "metadata": {
    "id": "HiU7cQiFVoQ9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "outputId": "17dc3e78-04e6-4cfc-b940-02164323cac5"
   },
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**(?) Get the videos**\n",
    "\n",
    "Requirements:\n",
    "* Create a folder called 'pred_folder' and save the predictions in this folder\n",
    "* Create a folder called 'video_folder' and save the videos in this folder"
   ],
   "metadata": {
    "id": "DYerh6P9WrQU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%cd corona"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7xGNR3i86JIS",
    "outputId": "02f1a82d-3629-47cd-912d-733c719f3789"
   },
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] Не удается найти указанный файл: 'corona'\n",
      "C:\\Users\\Eugene\\OneDrive\\Китай\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#(?) Create 'pred_folder' and 'video_folder'\n",
    "\n",
    "os.makedirs('video_folder_2layer', exist_ok=True)\n",
    "video_folder='video_folder_2layer'\n",
    "\n",
    "os.makedirs('pred_folder_2layer', exist_ok=True)\n",
    "pred_folder='pred_folder_2layer'\n",
    "\n",
    "data_dir = file_list[0]\n",
    "\n",
    "#\n",
    "num_frames = 40\n",
    "for file in file_list:\n",
    "    D = loadmat('data/' + file)['D']\n",
    "    D = torch.from_numpy(D).cfloat()\n",
    "    L = torch.empty(0)\n",
    "    S = torch.empty(0)\n",
    "    for k in range(0, D.shape[-1] - num_frames + 1, num_frames):\n",
    "        Dk = D[None, None, :, :, k:k + num_frames]\n",
    "        Dk = torch.cat([torch.real(Dk), torch.imag(Dk)], dim=-1)\n",
    "        Dk = Dk.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            Lk, Sk = net(Dk)\n",
    "\n",
    "        Lk = Lk[..., :num_frames].cpu().detach().squeeze()\n",
    "        Sk = Sk[..., :num_frames].cpu().detach().squeeze()\n",
    "\n",
    "        L = torch.cat([L, Lk], dim=-1)\n",
    "        S = torch.cat([S, Sk], dim=-1)\n",
    "\n",
    "    savemat('%s/prediction_%s' % (pred_folder, file), {'L': L.numpy(), 'S': S.numpy()})\n",
    "\n",
    "    D = torch.real(D[..., :L.shape[-1]])\n",
    "    V = np.round(torch.cat([D, L, S], dim=1).numpy() * 255)\n",
    "    array_to_gray_video(V, '%s/video_%s.mp4' % (video_folder, file[:-4]), fps=30)"
   ],
   "metadata": {
    "id": "vAatYM2zWrmc",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "bd115ca2-f664-4c14-9b3d-4eb718b083ae"
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
